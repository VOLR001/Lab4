{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c649b02a",
   "metadata": {},
   "source": [
    "# Lab: Pokémon Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89920876",
   "metadata": {},
   "source": [
    "## Objective\n",
    "This notebook demonstrates how to classify Pokémon as legendary or not using two machine learning models:\n",
    "- Logistic Regression\n",
    "- Multi-Layer Perceptron (MLP)\n",
    "\n",
    "We will compare the performance of both models using metrics such as accuracy, precision, recall, F1-score, and AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aea16b",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200d8967",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pokemon.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the Pokémon dataset\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m pokemon_data \u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpokemon.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display the first few rows\u001b[39;00m\n\u001b[0;32m      9\u001b[0m pokemon_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1403\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pokemon.xlsx'"
     ]
    }
   ],
   "source": [
    "# Your import \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# Load the Pokémon dataset\n",
    "pokemon_data =  pd.read_excel(\"pokemon.xlsx\")\n",
    "\n",
    "# Display the first few rows\n",
    "pokemon_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41159a0f",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing\n",
    "### 2.1 Feature Engineering\n",
    "\n",
    "### <span style=\"color:red\">Please create a derived feature: sp_attack_to_sp_defense_ratio, Target is Legendary</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ac0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a derived feature: sp_attack_to_sp_defense_ratio\n",
    "\n",
    "\n",
    "# your code\n",
    "\n",
    "# Select all features + derived  \n",
    "# target: Legendary \n",
    "# Your code\n",
    "\n",
    "X = pokemon_data[features] # Your code\n",
    "y = pokemon_data[target] # Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77742ab8",
   "metadata": {},
   "source": [
    "### 2.2 Data Transformation Using ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4085e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your import \n",
    "\n",
    "\n",
    "# Categorical and numerical columns\n",
    "# your code\n",
    "\n",
    "# Preprocessing pipeline\n",
    "# please choose one suitable method as your scaling method\n",
    "# please use OneHot as your Encoder\n",
    "# Your code\n",
    "\n",
    "preprocessor = # Your code\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c9d86-7fb5-4e3f-913a-9406a3aca34d",
   "metadata": {},
   "source": [
    "### Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aeb97f-35bc-47e0-b7d5-40b566202709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Transform the data\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "# Step 1: First train-test split to create training and temporary sets\n",
    "# X_transformed: Preprocessed feature data\n",
    "# y: Target labels\n",
    "# test_size=0.3: Reserve 30% of the data for validation and test sets\n",
    "# random_state=42: Ensures reproducibility of the splits\n",
    "# stratify=y: Maintains the class distribution in the split\n",
    "\n",
    "#Your code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898860c-76b1-4d97-b996-36fd9e9f1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your import \n",
    "\n",
    "# Please use train_test_split to prepare your data\n",
    "\n",
    "# Your code\n",
    "\n",
    "#Print your X_train and X_test\n",
    "X_train[:2], X_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655cee9",
   "metadata": {},
   "source": [
    "## Step 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Please build your Logistic Regression model\n",
    "\n",
    "\n",
    "\n",
    "# Train Logistic Regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Please use AUC and accuracy score to evaluate your model\n",
    "# By trying different methods, your accuracy can reach over 90%.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"<Your name> + Logistic Regression - Validation Performance:\")\n",
    "print(classification_report(y_val, y_val_pred_logistic))\n",
    "print(f\"Validation AUC: {auc_val_logistic:.4f}\")\n",
    "print(f\"Validation accuracy: {accuracy_score_logistic:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ac0fd",
   "metadata": {},
   "source": [
    "## Step 4: Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ab8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Please build your Multi-Layer Perceptron model\n",
    "\n",
    "# Hidden layer: 8 weights and 4 biases, activation: relu, iteration : 500\n",
    "# Your code\n",
    "\n",
    "\n",
    "# Please use AUC and accuracy score to evalue your model\n",
    "# By trying different methods, your accuracy can reach over 90%.\n",
    "# Your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train MLP Classifier\n",
    "\n",
    "\n",
    "# Evaluate MLP Classifier\n",
    "\n",
    "\n",
    "print(\"<Your name> + MLP Classifier - Validation Performance:\")\n",
    "print(classification_report(y_val, y_val_pred_mlp))\n",
    "print(f\"Validation AUC: {auc_val_mlp:.4f}\")\n",
    "print(f\"Validation accuracy: {accuracy_score_mlp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b5ac1c",
   "metadata": {},
   "source": [
    "## Step 5: Comparison of Models - Training Loss Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae23630-0dba-476f-81ad-ab35a8a938db",
   "metadata": {},
   "source": [
    "### Manually record the loss of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b222d-1400-48c9-a45a-0f7a1ad52715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "# Please record your loss of logistic regression with 500 iterations\n",
    "# Your code\n",
    "\n",
    "\n",
    "# Initialize the model with warm_start to fit incrementally\n",
    "\n",
    "\n",
    "# To store the loss values\n",
    "loss_curve = []\n",
    "\n",
    "# Train the model incrementally\n",
    "# Your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633829e-745e-427b-b877-c9069f48c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss during MLP training\n",
    "# Your code\n",
    " \n",
    "\n",
    "# Plot the loss difference during MLP training and Logistic\n",
    "# please set color of Logistic as green, set MLP as red.\n",
    "# Your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc460480-f995-46df-9419-e04606db0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "# Plot ROC Curve Comparison\n",
    "\n",
    "\n",
    "# Plot ROC curves\n",
    "# Your code \n",
    " \n",
    "# please set color of Logistic as green, set MLP as red.\n",
    "# Your code \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c09a5-a6c9-440d-bfce-3bf909c1c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your idea:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f17bd0",
   "metadata": {},
   "source": [
    "## Step 6: Visualization of Predictions and Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23617576",
   "metadata": {},
   "source": [
    "### 6.1 Actual vs Predicted Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8465fa-9bbe-407c-9e1e-6465356f7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please plot the Actual data and Predicted for Logistic and MLP model\n",
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130bacc-cf92-4d5b-afeb-c60d16363459",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3da9ce-c38d-4982-b238-61e348f95855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Logistic Regression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "# Logistic Regression\n",
    "\n",
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadff2d-a5bd-4bb2-b166-5e151a2bd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MLP\n",
    "# Your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4878c82",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88390e-931b-498f-9943-ead95b1fdb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please compare the difference and common between Logistic results and MLP results\n",
    "# Your idea :\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
